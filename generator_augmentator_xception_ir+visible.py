# -*- coding: utf-8 -*-
"""generator_augmentator_VGG16_IR+VISIBLE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jsuxDmm_h0jrOcY8OoV-hBVkavoQPsTc
"""

from google.colab import drive
drive.mount('/content/gdrive')

def preprocessing_image_ms(x, mean, std):
    # loop over image channels
    for idx, mean_value in enumerate(mean):
        x[..., idx] -= mean_value
        x[..., idx] /= std[idx]
    return x


def categorical_label_from_full_file_name(files, class_indices):
    from keras.utils import to_categorical
    import os
    # file basename without extension
    base_name = [os.path.splitext(os.path.basename(i))[0] for i in files]
    # class label from filename
    base_name = [i.split("_")[0] for i in base_name]
    # label to indices
    image_class = [class_indices[i] for i in base_name]
    # class indices to one-hot-label
    return to_categorical(image_class, num_classes=len(class_indices))

def hyperspectral_image_generator(files, class_indices, batch_size=32, image_mean=None,
                           rotation_range=0, shear_range=0, scale_range=1,
                           transform_range=0, horizontal_flip=False,
                           vertical_flip=False, crop=False, crop_size=None, filling_mode='edge',
                           speckle_noise=None):
    from skimage.io import imread
    import numpy as np
    from random import sample

    while True:
        # select batch_size number of samples without replacement
        batch_files = sample(files, batch_size)
        # get one_hot_label
        batch_Y = categorical_label_from_full_file_name(batch_files,
                                                        class_indices)
        # array for images
        batch_X = []
        # loop over images of the current batch
        for idx, input_path in enumerate(batch_files):
            image = np.array(imread(input_path), dtype=float)/ 255.0
            if image_mean is not None:
                mean_std_data = np.loadtxt(image_mean, delimiter=',')
                image = preprocessing_image_ms(image, mean_std_data[0], mean_std_data[1])
            # process image
            image = augmentation_image_ms(image, rotation_range=rotation_range, shear_range=shear_range,
                                          scale_range=scale_range,
                                          transform_range=transform_range, horizontal_flip=horizontal_flip,
                                          vertical_flip=vertical_flip, warp_mode=filling_mode)
            if speckle_noise is not None:
                from skimage.util import random_noise
                image_max = np.max(np.abs(image), axis=(0, 1))
                image /= image_max

                image = random_noise(image, mode='speckle', var=speckle_noise)
                image *= image_max

            if crop:
                if crop_size is None:
                    crop_size = image.shape[0:2]
                image = crop_image(image, crop_size)
            # put all together
            batch_X += [image]
        # convert lists to np.array
        X = np.array(batch_X)
        Y = np.array(batch_Y)

        yield(X, Y)


def hyperspectral_image_generator_jp2(files, shape_file, class_indices_column, batch_size=32, image_mean=None,
                                      rotation_range=0, shear_range=0, scale_range=1,
                                      transform_range=0, horizontal_flip=False,
                                      vertical_flip=False, crop_size=None, filling_mode='edge',
                                      speckle_noise=None):
    from rasterio.mask import mask
    from rasterio import open
    from shapely.geometry import box
    import geopandas as gpd
    import numpy as np
    from random import sample
    from keras.utils import to_categorical

    geometry_df = gpd.read_file(shape_file)
    centroids = geometry_df['geometry'].values
    class_indices = geometry_df[class_indices_column].values.astype(int)
    number_of_classes = class_indices.max()
    files_centroids = list(zip(files*len(centroids), list(centroids)*len(files), list(class_indices)*len(files)))
    while True:
        # select batch_size number of samples without replacement
        batch_files = sample(files_centroids, batch_size)
        # get one_hot_label

        batch_Y = []
        # array for images
        batch_X = []
        # loop over images of the current batch
        for idx, (rf, polycenter, label) in enumerate(batch_files):
            raster_file = open(rf)
            mask_polygon = box(max(polycenter.coords.xy[0][0] - raster_file.transform[0] * crop_size[0] * 2,
                                   raster_file.bounds.left),
                               max(polycenter.coords.xy[1][0] - raster_file.transform[4] * crop_size[1] * 2,
                                   raster_file.bounds.bottom),
                               min(polycenter.coords.xy[0][0] + raster_file.transform[0] * crop_size[0] * 2,
                                   raster_file.bounds.right),
                               min(polycenter.coords.xy[1][0] + raster_file.transform[4] * crop_size[1] * 2,
                                   raster_file.bounds.top))
            image, out_transform = mask(raster_file, shapes=[mask_polygon], crop=True, all_touched=True)
            image = np.transpose(image, (1, 2, 0))
            if image_mean is not None:
                mean_std_data = np.loadtxt(image_mean, delimiter=',')
                image = preprocessing_image_ms(image.astype(np.float64), mean_std_data[0], mean_std_data[1])
            # process image
            image = augmentation_image_ms(image, rotation_range=rotation_range, shear_range=shear_range,
                                          scale_range=scale_range,
                                          transform_range=transform_range, horizontal_flip=horizontal_flip,
                                          vertical_flip=vertical_flip, warp_mode=filling_mode)
            if speckle_noise is not None:
                from skimage.util import random_noise
                image_max = np.max(np.abs(image), axis=(0, 1))
                image /= image_max

                image = random_noise(image, mode='speckle', var=speckle_noise)
                image *= image_max

            image = crop_image(image, crop_size)

            # put all together
            batch_X += [image]
            batch_Y += [to_categorical(label, num_classes=number_of_classes)]
        # convert lists to np.array
        X = np.array(batch_X)
        Y = np.array(batch_Y)

        yield(X, Y)


def augmentation_image_ms(image, rotation_range=0, shear_range=0, scale_range=1, transform_range=0,
                          horizontal_flip=False, vertical_flip=False, warp_mode='edge'):
    from skimage.transform import AffineTransform, SimilarityTransform, warp
    from numpy import deg2rad, flipud, fliplr
    from numpy.random import uniform, random_integers
    from random import choice

    image_shape = image.shape
    # Generate image transformation parameters
    rotation_angle = uniform(low=-abs(rotation_range), high=abs(rotation_range))
    shear_angle = uniform(low=-abs(shear_range), high=abs(shear_range))
    scale_value = uniform(low=abs(1 / scale_range), high=abs(scale_range))
    translation_values = (random_integers(-abs(transform_range), abs(transform_range)),
                          random_integers(-abs(transform_range), abs(transform_range)))

    # Horizontal and vertical flips
    if horizontal_flip:
        # randomly flip image up/down
        if choice([True, False]):
            image = flipud(image)
    if vertical_flip:
        # randomly flip image left/right
        if choice([True, False]):
            image = fliplr(image)

    # Generate transformation object
    transform_toorigin = SimilarityTransform(scale=(1, 1), rotation=0, translation=(-image_shape[0], -image_shape[1]))
    transform_revert = SimilarityTransform(scale=(1, 1), rotation=0, translation=(image_shape[0], image_shape[1]))
    transform = AffineTransform(scale=(scale_value, scale_value), rotation=deg2rad(rotation_angle),
                                shear=deg2rad(shear_angle), translation=translation_values)
    # Apply transform
    image = warp(image, ((transform_toorigin) + transform) + transform_revert, mode=warp_mode, preserve_range=True)
    return image


def crop_image(image, target_size):
    from numpy import ceil, floor
    x_crop = min(image.shape[0], target_size[0])
    y_crop = min(image.shape[1], target_size[1])
    midpoint = [ceil(image.shape[0] / 2), ceil(image.shape[1] / 2)]

    out_img = image[int(midpoint[0] - ceil(x_crop / 2)):int(midpoint[0] + floor(x_crop / 2)),
              int(midpoint[1] - ceil(y_crop / 2)):int(midpoint[1] + floor(y_crop / 2)),
              :]
    assert list(out_img.shape[0:2]) == target_size
    return out_img

from glob import glob
import matplotlib.pyplot as plt

# variables
path_to_images = '/content/gdrive/My Drive/TFM/TODO_TIFF'
batch_size = 32
class_indices = {'red': 0, 'green': 1, 'black': 2}

no_augmentation_parameters = {'flip': False,
                            'zoom': 1.0,
                            'shift': 0.0,
                            'rotation': 0.0,
                            'sheer': 0.0,
                            'noising': None}
augmentation_parameters = {'flip': True,
                            'zoom': 1.4,
                            'shift': 0.15,
                            'rotation': 20.0,
                            'sheer': 0.015,
                            'noising': None}

#/content/gdrive/My Drive/TFM/TODO_TIFF/black_100a.tiff
image_files = glob(path_to_images + "/*.tiff")
print(image_files)

noaug_image_generator = hyperspectral_image_generator(image_files, class_indices,
                                                batch_size=batch_size,
                                                image_mean=None,
                                                rotation_range=no_augmentation_parameters['rotation'],
                                                horizontal_flip=no_augmentation_parameters['flip'],
                                                vertical_flip=no_augmentation_parameters['flip'],
                                                speckle_noise=no_augmentation_parameters['noising'],
                                                shear_range=no_augmentation_parameters['sheer'],
                                                scale_range=no_augmentation_parameters['zoom'],
                                                transform_range=no_augmentation_parameters['shift']
                                                )
aug_image_generator = hyperspectral_image_generator(image_files, class_indices,
                                                batch_size=batch_size,
                                                image_mean=None,
                                                rotation_range=augmentation_parameters['rotation'],
                                                horizontal_flip=augmentation_parameters['flip'],
                                                vertical_flip=augmentation_parameters['flip'],
                                                speckle_noise=augmentation_parameters['noising'],
                                                shear_range=augmentation_parameters['sheer'],
                                                scale_range=augmentation_parameters['zoom'],
                                                transform_range=augmentation_parameters['shift']
                                                )

# No augmentation case
data = next(noaug_image_generator)
images = data[0]
print(images.shape)
fig, axs = plt.subplots(1, 4, figsize=(10, 3))
for idx, ax in enumerate(axs):
    ax.imshow(images[idx, :, :, 1], cmap='gray')
    ax.axis('off')
plt.show()

images[idx, :, :, 1]

# Augmentation case
data = next(aug_image_generator)
images = data[0]
print(images.shape)
fig, axs = plt.subplots(1, 4, figsize=(10, 3))
for idx, ax in enumerate(axs):
    ax.imshow(images[idx, :, :, 1], cmap='gray')
    ax.axis('off')
plt.show()

from keras.applications import VGG16
conv_base = VGG16(weights=None,
include_top=False,
input_shape=(128, 128, 37))

from keras import models
from keras import layers
model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(2048, activation='relu'))
model.add(layers.Dense(1024, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(3, activation='softmax'))

model.summary()

from keras import models
from keras import layers
from keras import optimizers

model.compile(optimizer='adam',
loss='categorical_crossentropy',
metrics=['acc','mse'])

len(image_files)

len(image_files)*0.6

len(image_files)*0.2

367+122

import random
random.seed(30)
random.shuffle(image_files)

train_data = image_files[:367]
validation_data = image_files[367:489]
test_data = image_files[489:]

no_augmentation_parameters = {'flip': False,
                            'zoom': 1.0,
                            'shift': 0.0,
                            'rotation': 0.0,
                            'sheer': 0.0,
                            'noising': None}
augmentation_parameters = {'flip': True,
                            'zoom': 1.2,
                            'shift': 0.15,
                            'rotation': 20.0,
                            'sheer': 0.015,
                            'noising': None}

validation_generator = hyperspectral_image_generator(validation_data, class_indices,
                                                batch_size=32,
                                                image_mean=None,
                                                rotation_range=no_augmentation_parameters['rotation'],
                                                horizontal_flip=no_augmentation_parameters['flip'],
                                                vertical_flip=no_augmentation_parameters['flip'],
                                                speckle_noise=no_augmentation_parameters['noising'],
                                                shear_range=no_augmentation_parameters['sheer'],
                                                scale_range=no_augmentation_parameters['zoom'],
                                                transform_range=no_augmentation_parameters['shift']
                                                )
train_generator = hyperspectral_image_generator(train_data, class_indices,
                                                batch_size=32,
                                                image_mean=None,
                                                rotation_range=augmentation_parameters['rotation'],
                                                horizontal_flip=augmentation_parameters['flip'],
                                                vertical_flip=augmentation_parameters['flip'],
                                                speckle_noise=augmentation_parameters['noising'],
                                                shear_range=augmentation_parameters['sheer'],
                                                scale_range=augmentation_parameters['zoom'],
                                                transform_range=augmentation_parameters['shift']
                                                )

# Augmentation case
data = next(train_generator)
images = data[0]
print(images.shape)
fig, axs = plt.subplots(1, 4, figsize=(10, 3))
for idx, ax in enumerate(axs):
    ax.imshow(images[idx, :, :, 1], cmap='gray')
    ax.axis('off')
plt.show()

len(train_data) // batch_size

history = model.fit(train_generator,
                    steps_per_epoch=len(train_data) // batch_size,
                    epochs=25,
                    validation_data=validation_generator,
                    validation_steps=5)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/TFM

model.save('VGG16_augmentator_IR+VISI_50epoch_categorical_accuracy.h5')

import matplotlib.pyplot as plt
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.clf()
acc = history.history['acc']
val_acc = history.history['val_acc']
plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.clf()
acc = history.history['mse']
val_acc = history.history['val_mse']
plt.plot(epochs, acc, 'bo', label='Training mse')
plt.plot(epochs, val_acc, 'b', label='Validation mse')
plt.title('Training and validation MSE')
plt.xlabel('Epochs')
plt.ylabel('MSE')
plt.legend()
plt.show()

test_data

import keras

model = keras.models.load_model('/content/gdrive/My Drive/TFM/VGG16_augmentator_IR+VISI_50epoch.h5')

test_generator = hyperspectral_image_generator(test_data, class_indices,
                                                batch_size=32,
                                                image_mean=None,
                                                rotation_range=no_augmentation_parameters['rotation'],
                                                horizontal_flip=no_augmentation_parameters['flip'],
                                                vertical_flip=no_augmentation_parameters['flip'],
                                                speckle_noise=no_augmentation_parameters['noising'],
                                                shear_range=no_augmentation_parameters['sheer'],
                                                scale_range=no_augmentation_parameters['zoom'],
                                                transform_range=no_augmentation_parameters['shift']
                                                )

results = model.evaluate(test_generator, steps=5)

results
